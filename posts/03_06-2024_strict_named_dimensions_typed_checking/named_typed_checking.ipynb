{
 "cells": [
  {
   "cell_type": "raw",
   "id": "883f95e5-c483-4270-b199-8d6b0b47a450",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Strict typed named dimension checking\"\n",
    "author: \"Andrej Muhic\"\n",
    "date: \"2024-06-03\"\n",
    "categories: [Engineering, Coding]\n",
    "image: \"decorated_named_dimensions.png\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "    code-tools: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9e982-ea4d-42d0-aba6-0a692fc27089",
   "metadata": {},
   "source": [
    "# Named dimensions\n",
    "- [PyTorch named tensor](https://pytorch.org/docs/stable/named_tensor.html)\n",
    "- [Jax Typing](https://docs.kidger.site/jaxtyping/) [Line annotations does not work as expected yet.](https://github.com/patrick-kidger/jaxtyping/issues/153)\n",
    "\n",
    "We will look at Jax Typing and how to do named dimension checking with a code example. This is really useful as the code is much easier to read and on top of that input and output dimensions are checked. This probably only real option currently as sadly Pytorch named tensor project is mainly abandoned? Let us proceed to code example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfcaae38-8c79-4d74-bbf4-0f562d248511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:52:41.100129Z",
     "start_time": "2024-06-03T19:52:39.719497Z"
    }
   },
   "outputs": [],
   "source": [
    "import typing\n",
    "from typing import Optional, Union, Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "from jaxtyping import Float, Int64, jaxtyped\n",
    "# Use your favourite typechecker: usually one of the two lines below.\n",
    "import beartype\n",
    "from typeguard import typechecked as typechecker\n",
    "%reload_ext jaxtyping\n",
    "%jaxtyping.typechecker beartype.beartype\n",
    "#jaxtyping.install_import_hook(module, typechecker=beartype.beartype)\n",
    "\n",
    "Array: typing.TypeAlias = torch.Tensor\n",
    "Long: typing.TypeAlias = Int64\n",
    "\n",
    "vocab_size = 65\n",
    "token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "\n",
    "#@jaxtyped(typechecker=typechecker)\n",
    "def forward(idx: Long[torch.Tensor, \"batch_dim context_dim\"],\n",
    "            targets: Optional[Long[torch.Tensor, \"batch_dim context_dim\"]] = None) -> Tuple[\n",
    "    Union[Float[torch.Tensor, \"batch_dim*context_dim latent_dim\"], Float[\n",
    "        torch.Tensor, \"batch_dim context_dim latent_dim\"]], Union[Float[torch.Tensor, \"\"], None]]:\n",
    "    # idx and targets are both (B,T) tensor of integers\n",
    "    logits: Long[torch.Tensor, \"batch_dim context_dim latent_dim\"] = token_embedding_table(\n",
    "        idx)  # (B,T,C=vocab_size)\n",
    "    if targets is None:\n",
    "        return logits, None\n",
    "    else:\n",
    "        # Note that here strictly speaking this does not fix batch size explicitly to B\n",
    "        B, T, C = logits.shape  # (B,T,C=vocab_size)\n",
    "        # Just a hack to avoid transposing, cross_entropy expects B x C x T in batched mode\n",
    "        # This converts into non batched mode\n",
    "        logits: Long[torch.Tensor, \"batch_dim*context_dim latent_dim\"] = logits.view(B * T, C)\n",
    "        # The above is clearly wrong but will not be checked currently\n",
    "        targets: Long[torch.Tensor, \"batch_dim*context_dim\"] = targets.view(B * T)\n",
    "        # https://agustinus.kristia.de/techblog/2016/12/21/forward-reverse-kl/\n",
    "        loss: Float[torch.Tensor, \"\"] = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "idx = torch.randint(low=0, high=65, size=(256, 65))\n",
    "targets = torch.randint(low=0, high=65, size=(256, 65))\n",
    "out_not_none = forward(idx, targets)\n",
    "out_none = forward(idx, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
